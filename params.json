{"name":"PHP-Spider","tagline":"A configurable and extensible PHP web spider","body":"[![Build Status](https://travis-ci.org/mvdbos/php-spider.png?branch=master)](https://travis-ci.org/mvdbos/php-spider)\r\n[![Coverage Status](https://coveralls.io/repos/mvdbos/php-spider/badge.svg?branch=master&service=github)](https://coveralls.io/github/mvdbos/php-spider?branch=master)\r\n[![Scrutinizer Code Quality](https://scrutinizer-ci.com/g/mvdbos/php-spider/badges/quality-score.png?b=master)](https://scrutinizer-ci.com/g/mvdbos/php-spider/?branch=master)\r\n[![Dependency Status](https://www.versioneye.com/php/vdb:php-spider/dev-master/badge)](https://www.versioneye.com/php/vdb:php-spider/dev-master)\r\n\r\n[![Latest Stable Version](https://poser.pugx.org/vdb/php-spider/v/stable)](https://packagist.org/packages/vdb/php-spider)\r\n[![License](https://poser.pugx.org/vdb/php-spider/license)](https://packagist.org/packages/vdb/php-spider)\r\n\r\n\r\nPHP-Spider Features\r\n======\r\n- supports two traversal algorithms: breadth-first and depth-first\r\n- supports crawl depth limiting, queue size limiting and max downloads limiting\r\n- supports adding custom URI discovery logic, based on XPath, CSS selectors, or plain old PHP\r\n- comes with a useful set of URI filters, such as Domain limiting\r\n- supports custom URI filters, both prefetch (URI) and postfetch (Resource content)\r\n- supports custom request handling logic\r\n- comes with a useful set of persistence handlers (memory, file. Redis soon to follow)\r\n- supports custom persistence handlers\r\n- collects statistics about the crawl for reporting\r\n- dispatches useful events, allowing developers to add even more custom behavior\r\n- supports a politeness policy\r\n- will soon come with many default discoverers: RSS, Atom, RDF, etc.\r\n- will soon support multiple queueing mechanisms (file, memcache, redis)\r\n- will eventually support distributed spidering with a central queue\r\n\r\nInstallation\r\n------------\r\nThe easiest way to install PHP-Spider is with [composer](http://getcomposer.org/).  Find it on [Packagist](https://packagist.org/packages/vdb/php-spider).\r\n\r\nUsage\r\n-----\r\nThis is a very simple example. This code can be found in [example/example_simple.php](https://github.com/matthijsvandenbos/php-spider/blob/master/example/example_simple.php). For a more complete example with some logging, caching and filters, see [example/example_complex.php](https://github.com/matthijsvandenbos/php-spider/blob/master/example/example_complex.php). That file contains a more real-world example.\r\n\r\nFirst create the spider\r\n```php\r\n$spider = new Spider('http://www.dmoz.org');\r\n```\r\nAdd a URI discoverer. Without it, the spider does nothing. In this case, we want all `<a>` nodes from a certain `<div>`\r\n\r\n```php\r\n$spider->getDiscovererSet()->set(new XPathExpressionDiscoverer(\"//div[@id='catalogs']//a\"));\r\n```\r\nSet some sane options for this example. In this case, we only get the first 10 items from the start page.\r\n\r\n```php\r\n$spider->getDiscovererSet()->maxDepth = 1;\r\n$spider->getQueueManager()->maxQueueSize = 10;\r\n```\r\nAdd a listener to collect stats from the Spider and the QueueManager.\r\nThere are more components that dispatch events you can use.\r\n\r\n```php\r\n$statsHandler = new StatsHandler();\r\n$spider->getQueueManager()->getDispatcher()->addSubscriber($statsHandler);\r\n$spider->getDispatcher()->addSubscriber($statsHandler);\r\n```\r\nExecute the crawl\r\n\r\n```php\r\n$spider->crawl();\r\n```\r\nWhen crawling is done, we could get some info about the crawl\r\n```php\r\necho \"\\n  ENQUEUED:  \" . count($statsHandler->getQueued());\r\necho \"\\n  SKIPPED:   \" . count($statsHandler->getFiltered());\r\necho \"\\n  FAILED:    \" . count($statsHandler->getFailed());\r\necho \"\\n  PERSISTED:    \" . count($statsHandler->getPersisted());\r\n```\r\nFinally we could do some processing on the downloaded resources. In this example, we will echo the title of all resources\r\n```php\r\necho \"\\n\\nDOWNLOADED RESOURCES: \";\r\nforeach ($spider->getDownloader()->getPersistenceHandler() as $resource) {\r\n    echo \"\\n - \" . $resource->getCrawler()->filterXpath('//title')->text();\r\n}\r\n\r\n```\r\nContributing\r\n------------\r\nContributing to PHP-Spider is as easy as Forking the repository on Github and submitting a Pull Request.\r\nThe Symfony documentation contains an excellent guide for how to do that properly here: [Submitting a Patch](http://symfony.com/doc/current/contributing/code/patches.html#step-1-setup-your-environment).\r\n\r\nThere a few requirements for a Pull Request to be accepted:\r\n- Follow the coding standards: PHP-Spider follows the coding standards defined in the [PSR-0](https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-0.md), [PSR-1](https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-1-basic-coding-standard.md) and [PSR-2](https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-2-coding-style-guide.md) Coding Style Guides;\r\n- Prove that the code works with unit tests;\r\n\r\n> Note: An easy way to check if your code conforms to PHP-Spider is by running [PHP CodeSniffer](https://github.com/squizlabs/PHP_CodeSniffe/) on your local code. Please make sure you use the PSR-2 standard: `--standard=PSR2`\r\n\r\nSupport\r\n-------\r\nFor things like reporting bugs and requesting features it is best to create an [issue](https://github.com/matthijsvandenbos/php-spider/issues) here on GitHub. It is even better to accompany it with a Pull Request. ;-)\r\n\r\nLicense\r\n-------\r\nPHP-Spider is licensed under the MIT license.\r\n","google":"UA-38994599-1","note":"Don't delete this file! It's used internally to help with page regeneration."}