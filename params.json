{"name":"PHP-Spider","tagline":"A configurable and extensible PHP web spider","body":"PHP-Spider Features\r\n======\r\n- supports two traversal algorithms: breadth-first and depth-first\r\n- supports depth limiting and queue size limiting\r\n- supports adding custom URI discovery logic, based on XPath, CSS selectors, or plain old PHP\r\n- comes with a useful set of prebuilt URI filters, such as Domain limiting\r\n- supports custom filters, both prefetch (URI) and postfetch (Resource content)\r\n- supports custom request handling logic\r\n- dispatches useful events, allowing developers to add even more custom behavior\r\n- supports a politeness policy\r\n- will soon come with many default discoverers: RSS, Atom, RDF, etc.\r\n- will soon support multiple queueing and persistence mechanisms (file, memcache, redis)\r\n- will eventually support distributed spidering with a central queue\r\n\r\nUsage\r\n-----\r\nThis is a very simple example. This code can be found in [example/example_simple.php](https://github.com/matthijsvandenbos/php-spider/blob/master/example/example_simple.php). For a more complete example with\r\nsome logging, caching and filters, see [example/example_complex.php](https://github.com/matthijsvandenbos/php-spider/blob/master/example/example_complex.php). That file contains a more real-world example.\r\n\r\nFirst create the spider\r\n```php\r\nuse VDB\\Spider\\Spider;\r\nuse VDB\\Spider\\Discoverer\\XPathExpressionDiscoverer;\r\n\r\n$spider = new Spider('http://www.dmoz.org');\r\n```\r\nAdd a URI discoverer. Without it, the spider does nothing. In this case, we want all `<a>` nodes from a certain `<div>`\r\n\r\n```php\r\n$spider->addDiscoverer(new XPathExpressionDiscoverer(\"//div[@id='catalogs']//a\"));\r\n```\r\nSet some sane options for this example. In this case, we only get the first 10 items from the start page.\r\n```php\r\n$spider->setMaxDepth(1);\r\n$spider->setMaxQueueSize(10);\r\n```\r\nExecute crawl\r\n```php\r\n$report = $spider->crawl();\r\n```\r\nAnd finally, we could get some info about the crawl\r\n```php\r\necho \"\\nENQUEUED: \" . count($report['queued']);\r\necho \"\\n - \".implode(\"\\n - \", $report['queued']);\r\necho \"\\nSKIPPED:   \" . count($report['filtered']);\r\necho \"\\nFAILED:    \" . count($report['failed']) . \"\\n\";\r\n```\r\nCONTRIBUTING\r\n------------\r\nContributing to PHP-Spider is as easy as Forking the repository on Github and submitting a Pull Request. \r\nThe Symfony documentation contains an excellent guide for how to do that properly here: [Submitting a Patch](http://symfony.com/doc/current/contributing/code/patches.html#step-1-setup-your-environment).\r\n\r\nThere a few requirements for a Pull Request to be accepted:\r\n- Follow the coding standards: PHP-Spider follows the coding standards defined in the [PSR-0](https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-0.md), [PSR-1](https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-1-basic-coding-standard.md) and [PSR-2](https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-2-coding-style-guide.md) Coding Style Guides;\r\n- Prove that the code works with unit tests;\r\n\r\n> Note: An easy way to check if your code conforms to PHP-Spider is by running [Scrutinizer](https://scrutinizer-ci.com/) on your local code. You can do it simply by downloading [scrutinizer.phar](https://scrutinizer-ci.com/scrutinizer.phar) and running it on your PHP-Spider repository like so: `php scrutinizer.phar run /path/to/php-spider`\r\n\r\nLICENSE\r\n-------\r\nPHP-Spider is licensed under the MIT license.\r\n","google":"UA-38994599-1","note":"Don't delete this file! It's used internally to help with page regeneration."}